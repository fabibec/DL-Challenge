{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "929afcb6",
   "metadata": {},
   "source": [
    "# Generative Model\n",
    "\n",
    "This notebook deals with finding a good generative model.\n",
    "\n",
    "# TODO: VAE, Diffusion Model & (Sharpening U-Net GAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc0f9e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import import_ipynb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import LambdaLR, ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary\n",
    "from utils import DEVICE, classes, train_data, test_data, BaseModule, train_transforms, QuickDrawDataset # type: ignore\n",
    "import os\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import umap.umap_ as umap\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "354591b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "\n",
    "# Hyperparameters\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 100\n",
    "PATIENCE = 100\n",
    "ALPHA = 0.1\n",
    "\n",
    "# Data loaders\n",
    "TRAIN_LOADER = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, num_workers=6)\n",
    "TEST_LOADER = DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=6)\n",
    "\n",
    "# LR scheduler lambda function\n",
    "def lr_lambda(epoch):\n",
    "    return 0.95 ** (epoch - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a13d3e",
   "metadata": {},
   "source": [
    "## Conditional Variatonal Autoencoder\n",
    "\n",
    "First of all I want to start with a CNN-based variatonal Autoencoder. This way I can apply the knowledge that I gained while building the Classifier Model earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ce2e40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VAE loss function - combines reconstruction loss and KL divergence\n",
    "def vae_loss(recon_x, x, mu, logvar, beta=1.0):\n",
    "    BCE = F.mse_loss(recon_x, x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE, KLD, (BCE + beta * KLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3a45322a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Conditional Variational Autoencoder (CVAE) model\n",
    "class CVAE(nn.Module):\n",
    "    def __init__(self, latent_dim=30, num_classes=len(classes)):\n",
    "        super(CVAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # label embedding to inject the information into the encoder\n",
    "        self.label_embed_conv = nn.Linear(num_classes, 28 * 28)\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(2, 32, kernel_size=3, padding=1),  # 1 channel image + 1 channel label map\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Dropout(0.3),\n",
    "        )\n",
    "\n",
    "        # Latent mappings\n",
    "        self.fc_input_dim = 64 * 7 * 7\n",
    "        self.fc_mu = nn.Linear(self.fc_input_dim, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(self.fc_input_dim, latent_dim)\n",
    "\n",
    "        # Decoder\n",
    "        self.fc_decode = nn.Linear(latent_dim + num_classes, 64 * 7 * 7)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "\n",
    "            nn.Conv2d(32, 1, kernel_size=3, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    # Reparameterization trick to sample from the latent space\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # One-hot label to image-size label map\n",
    "        y_onehot = F.one_hot(y, self.num_classes).float().to(x.device)\n",
    "        y_map = self.label_embed_conv(y_onehot).view(batch_size, 1, 28, 28)\n",
    "\n",
    "        # Concatenate image and label map\n",
    "        x_cat = torch.cat([x, y_map], dim=1)\n",
    "\n",
    "        x_encoded = self.encoder(x_cat)\n",
    "        x_flat = x_encoded.view(batch_size, -1)\n",
    "\n",
    "        mu = self.fc_mu(x_flat)\n",
    "        logvar = self.fc_logvar(x_flat)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "\n",
    "        # Decode\n",
    "        z_cat = torch.cat([z, y_onehot], dim=1)\n",
    "        x_decoded = self.fc_decode(z_cat)\n",
    "        x_decoded = x_decoded.view(batch_size, 64, 7, 7)\n",
    "        recon_x = self.decoder(x_decoded)\n",
    "\n",
    "        return recon_x, mu, logvar, z\n",
    "\n",
    "    def sample(self, z, y):\n",
    "        y_onehot = F.one_hot(y, self.num_classes).float().to(z.device)\n",
    "        z_cat = torch.cat([z, y_onehot], dim=1)\n",
    "        x_decoded = self.fc_decode(z_cat)\n",
    "        x_decoded = x_decoded.view(z.size(0), 64, 7, 7)\n",
    "        samples = self.decoder(x_decoded)\n",
    "        return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ff9e0e42-f3ba-4173-aad7-2ffe63bef230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_anneal(epoch, total_epochs, max_beta=1.0):\n",
    "    \"\"\"Linear annealing from 0 to max_beta\"\"\"\n",
    "    return min(max_beta, max_beta * epoch / total_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03423541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_conditional_images(model, epoch, num_classes=5, latent_dim=50, device=DEVICE):\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(num_classes, latent_dim).to(device)\n",
    "        y = torch.arange(num_classes).to(device)\n",
    "        samples = model.sample(z, y).cpu()\n",
    "\n",
    "        _, axes = plt.subplots(1, num_classes, figsize=(num_classes*2, 2))\n",
    "        for i in range(num_classes):\n",
    "            ax = axes[i]\n",
    "            ax.imshow(samples[i].squeeze(), cmap='gray')\n",
    "            ax.axis('off')\n",
    "            ax.set_title(classes[i])\n",
    "\n",
    "        plt.suptitle(f'Sampled Images at Epoch {epoch}', y=1.05)\n",
    "        plt.subplots_adjust(top=0.8)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64faa8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots a UMAP projection to visualize the latent space of the model\n",
    "def plot_umap(z_all, y_all, epoch, class_names):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=FutureWarning)\n",
    "        reducer = umap.UMAP(n_components=2, random_state=None)\n",
    "    z_2d = reducer.fit_transform(z_all)\n",
    "\n",
    "    # Get unique classes sorted to align with colorbar ticks\n",
    "    unique_classes = sorted(set(y_all))\n",
    "\n",
    "    # Create a dict mapping class index to name\n",
    "    class_labels = [class_names[c] for c in unique_classes]\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    scatter = plt.scatter(z_2d[:, 0], z_2d[:, 1], c=y_all, cmap='tab10', alpha=0.6)\n",
    "\n",
    "    # Setup colorbar with ticks and labels\n",
    "    cbar = plt.colorbar(scatter, ticks=unique_classes)\n",
    "    cbar.ax.set_yticklabels(class_labels)\n",
    "\n",
    "    plt.title(f't-SNE Projection of Latent Space at Epoch {epoch}')\n",
    "    plt.xlabel(\"t-SNE dim 1\")\n",
    "    plt.ylabel(\"t-SNE dim 2\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4da84126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Learning Rate 0.0010\n",
      "Loss: 494.6105 | Reconstruction Loss: 494.6105 | KL Divergence: 1404.4871\n",
      "Epoch 2 | Learning Rate 0.0010\n",
      "Loss: 489.6196 | Reconstruction Loss: 486.6942 | KL Divergence: 390.0529\n",
      "Epoch 3 | Learning Rate 0.0010\n",
      "Loss: 473.7422 | Reconstruction Loss: 470.9821 | KL Divergence: 184.0110\n",
      "Epoch 4 | Learning Rate 0.0010\n",
      "Loss: 468.7465 | Reconstruction Loss: 465.7930 | KL Divergence: 131.2632\n",
      "Epoch 5 | Learning Rate 0.0010\n",
      "Loss: 460.9281 | Reconstruction Loss: 457.5090 | KL Divergence: 113.9701\n",
      "Epoch 6 | Learning Rate 0.0010\n",
      "Loss: 464.4125 | Reconstruction Loss: 460.4221 | KL Divergence: 106.4115\n",
      "Epoch 7 | Learning Rate 0.0010\n",
      "Loss: 467.5361 | Reconstruction Loss: 462.7633 | KL Divergence: 106.0622\n",
      "Epoch 8 | Learning Rate 0.0010\n",
      "Loss: 451.6958 | Reconstruction Loss: 446.3664 | KL Divergence: 101.5134\n",
      "Epoch 9 | Learning Rate 0.0010\n",
      "Loss: 466.2854 | Reconstruction Loss: 460.2732 | KL Divergence: 100.2029\n",
      "Epoch 10 | Learning Rate 0.0010\n",
      "Loss: 466.5759 | Reconstruction Loss: 459.9458 | KL Divergence: 98.2231\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Learning Rate 0.0010\n",
      "Loss: 475.8627 | Reconstruction Loss: 468.4706 | KL Divergence: 98.5613\n",
      "Epoch 12 | Learning Rate 0.0010\n",
      "Loss: 452.3862 | Reconstruction Loss: 444.7722 | KL Divergence: 92.2904\n",
      "Epoch 13 | Learning Rate 0.0010\n",
      "Loss: 454.4754 | Reconstruction Loss: 445.9196 | KL Divergence: 95.0645\n",
      "Epoch 14 | Learning Rate 0.0010\n",
      "Loss: 464.6582 | Reconstruction Loss: 455.7041 | KL Divergence: 91.8371\n",
      "Epoch 15 | Learning Rate 0.0010\n",
      "Loss: 471.5575 | Reconstruction Loss: 461.7168 | KL Divergence: 93.7211\n",
      "Epoch 16 | Learning Rate 0.0010\n",
      "Loss: 453.1899 | Reconstruction Loss: 443.0174 | KL Divergence: 90.4221\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     40\u001b[39m loss.append(train_loss.item()/\u001b[38;5;28mlen\u001b[39m(x))\n\u001b[32m     42\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m \u001b[43mtrain_loss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m optimizer.step()\n\u001b[32m     46\u001b[39m z_all.append(z.detach().cpu())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/dist-packages/torch/_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/dist-packages/torch/autograd/__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.13/dist-packages/torch/autograd/graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Training and evaluation loop for the CVAE model\n",
    "\n",
    "kl = []\n",
    "recon = []\n",
    "loss = []\n",
    "\n",
    "# Beta parameter for KL divergence weighting\n",
    "\"\"\"\n",
    "beta = 5 caused KL Divergence to collapse\n",
    "beta = 2 training plateaued after 10 epochs\n",
    "\"\"\"\n",
    "beta = 0.75\n",
    "\n",
    "model = CVAE().to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "#scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.9)\n",
    "# Params for early stopping\n",
    "best_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "\n",
    "# Create directories for saving weights if they don't exist\n",
    "os.makedirs(os.path.dirname(f'../weights/generative/cvae.pt'), exist_ok=True)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "    z_all = []\n",
    "    y_all = []\n",
    "\n",
    "    for i, (x, labels) in enumerate(TRAIN_LOADER):\n",
    "        x = x.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        x_reconst, mu, log_var, z = model(x,labels)\n",
    "        current_beta = kl_anneal(epoch, NUM_EPOCHS, beta)\n",
    "        reconst_loss, kl_div, train_loss = vae_loss(x_reconst, x, mu, log_var, current_beta)\n",
    "\n",
    "        recon.append(reconst_loss.item()/len(x))\n",
    "        kl.append(kl_div.item()/len(x))\n",
    "        loss.append(train_loss.item()/len(x))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        z_all.append(z.detach().cpu())\n",
    "        y_all.append(labels.detach().cpu())\n",
    "\n",
    "    #scheduler.step(train_loss)\n",
    "\n",
    "    # Early stopping logic\n",
    "    if train_loss < best_loss:\n",
    "        best_loss = train_loss\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model, f'../weights/generative/cvae.pt')\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "\n",
    "    if epochs_no_improve >= PATIENCE:\n",
    "        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Learning Rate {optimizer.param_groups[0]['lr']:.4f}\\n\"\n",
    "        f\"Loss: {train_loss.item()/len(x):.4f} | \"\n",
    "        f\"Reconstruction Loss: {reconst_loss.item()/len(x):.4f} | \"\n",
    "        f\"KL Divergence: {kl_div.item()/len(x):.4f}\")\n",
    "\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        model.eval()\n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            # Visualize the latent space using UMAP\n",
    "            z_all = torch.cat(z_all)\n",
    "            y_all = torch.cat(y_all)\n",
    "            plot_umap(z_all.numpy(), y_all.numpy(), epoch + 1, classes)\n",
    "        sample_conditional_images(model, epoch + 1, model.num_classes, model.latent_dim, DEVICE)\n",
    "        model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf3efab",
   "metadata": {},
   "source": [
    "## Conditional GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4604263",
   "metadata": {},
   "source": [
    "## Conditional Diffusion Model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
